{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport h5py\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# global setting\nBATCH_SIZE = 100\nNUM_CLASSES = 10\nEPOCHS = 50","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build Model "},{"metadata":{},"cell_type":"markdown","source":"![image.png](attachment:images/model.png)","attachments":{}},{"metadata":{},"cell_type":"markdown","source":"## Basic Blocks"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nblock for ResNet18 and ResNet34\ncorresponding to the \n[3x3,num_filter]\n[3x3,num_filter] \npart in Table 1\n\nstrides = 1 for 64 filters block\nstrides = 2 for [128, 256, 512] block (only first conv layer)\n\"\"\"\nclass Block3x3(tf.keras.layers.Layer):\n    def __init__(self, num_filter, strides):\n        super().__init__()\n        self.strides = strides\n        self.conv1 = tf.keras.layers.Conv2D(\n            filters=num_filter,\n            kernel_size=[3,3],\n            strides=strides,\n            padding=\"same\")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.conv2 = tf.keras.layers.Conv2D(\n            filters=num_filter,\n            kernel_size=[3,3],\n            strides=1, # strides for the second conv is 1 \n            padding=\"same\")\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        # functions to calcluate residual\n        if strides==1:\n            self.get_residual = lambda x:x\n        else:\n            self.get_residual = tf.keras.layers.Conv2D(\n                filters=num_filter,\n                kernel_size=[1,1],\n                strides=strides, # size of figure shrinks with same value\n                padding=\"same\")\n    \n    def call(self,inputs,training=None):\n        residual = self.get_residual(inputs)\n        # conv nets\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n        \n        # output = tf.nn.relu(tf.math.add(x,residual))\n        output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n        \n        return output      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nblock for ResNet50, ResNet101, and ResNet152\n\"Bottle Neck Block\"\n\"\"\"\nclass BlockBottleNeck(tf.keras.layers.Layer):\n    def __init__(self,num_filter1,strides):\n        super().__init__()\n        self.conv1 = tf.keras.layers.Conv2D(\n            filters=num_filter1,\n            kernel_size=[1, 1],\n            padding=\"same\",\n            strides=strides)\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.conv2 = tf.keras.layers.Conv2D(\n            filters=num_filter1,\n            kernel_size=[3, 3],\n            padding=\"same\",\n            strides=1)\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.conv3 = tf.keras.layers.Conv2D(\n            filters=num_filter1*4,\n            kernel_size=[1, 1],\n            padding=\"same\",\n            strides=1)\n        self.bn3 = tf.keras.layers.BatchNormalization()\n        \n        self.get_residual = tf.keras.layers.Conv2D(\n            filters=num_filter1*4,\n            kernel_size=[1, 1],\n            padding=\"same\",\n            strides=strides)\n    \n    def call(self,inputs, training=None):\n        residual = self.get_residual(inputs)\n        \n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.conv3(x)\n        x = self.bn3(x, training=training)\n        x = tf.math.add(x, residual)\n        \n        output = tf.nn.relu(x)\n        \n        return output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Blocks with the Same num_filter"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nblock for ResNet18 and ResNet34\ncorresponding to the \n[3x3,num_filter]\n[3x3,num_filter] x 2 \npart in Table 1 (one cell in table)\n\"\"\"\nclass Block3x3xn(tf.keras.layers.Layer):\n    def __init__(self, num_filter, num_block, strides):\n        super().__init__()\n        self.num_block = num_block\n        self.block1 = Block3x3(num_filter, strides) # could have stride\n        self.block_after2_list = []\n        for i in range(num_block-1):\n            self.block_after2_list.append(Block3x3(num_filter,1))\n            \n    def call(self, inputs, training=None):\n        x = self.block1(inputs, training=training)\n        for i in range(self.num_block-1):\n            x = self.block_after2_list[i](x, training=training)\n        output = x\n        \n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nfor ResNet50+\n\"\"\"\nclass BlockBottleNeckxn(tf.keras.layers.Layer):\n    def __init__(self,num_filter1, num_block,strides):\n        super().__init__()\n        self.num_block = num_block\n        self.block1 = BlockBottleNeck(num_filter1, strides)\n        self.block_after2_list = []\n        for i in range(num_block-1):\n            self.block_after2_list.append(BlockBottleNeck(num_filter1, strides))\n            \n    def call(self, inputs, training=None):\n        x = self.block1(inputs)\n        for i in range(self.num_block-1):\n            x = self.block_after2_list[i](x, training=training)\n        output = x\n        \n        return output      ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ResNet18 class\nclass ResNet18(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = tf.keras.layers.Conv2D(\n            filters=64,\n            kernel_size=[7, 7],\n            strides=2,\n            padding=\"same\")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.maxpooling1 = tf.keras.layers.MaxPool2D(\n            pool_size=[3, 3],\n            strides=2,\n            padding=\"same\")\n        # num_filter, num_block, stride for 1st conv layer\n        self.block1 = Block3x3xn(64, 2, 1)\n        self.block2 = Block3x3xn(128, 2, 2)\n        self.block3 = Block3x3xn(256, 2, 2)\n        self.block4 = Block3x3xn(512, 2, 2)\n        # average pooling \n        self.averagepooling = tf.keras.layers.GlobalAveragePooling2D()\n        self.dense = tf.keras.layers.Dense(units=NUM_CLASSES) # number of classes\n    \n    def call(self, inputs, training=None):\n        x = tf.image.resize(inputs,[224, 224])\n        x = self.conv1(x)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.maxpooling1(x)\n        x = self.block1(x, training=training)\n        x = self.block2(x, training=training)\n        x = self.block3(x, training=training)\n        x = self.block4(x, training=training)\n        x = self.averagepooling(x)\n        x = self.dense(x)\n        output = tf.nn.softmax(x)\n        \n        return output  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ResNet34 class\nclass ResNet34(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = tf.keras.layers.Conv2D(\n            filters=64,\n            kernel_size=[7, 7],\n            strides=2,\n            padding=\"same\")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.maxpooling1 = tf.keras.layers.MaxPool2D(\n            pool_size=[3, 3],\n            strides=2,\n            padding=\"same\")\n        # filters, num_block, strides\n        self.block1 = Block3x3xn(64, 3, 1)\n        self.block2 = Block3x3xn(128, 4, 2)\n        self.block3 = Block3x3xn(256, 6, 2)\n        self.block4 = Block3x3xn(512, 3, 2)\n        self.averagepooling = tf.keras.layers.GlobalAveragePooling2D()\n        self.dense = tf.keras.layers.Dense(units=NUM_CLASSES)\n        \n    def call(self, inputs, training=None):\n        x = tf.image.resize(inputs, [224, 224])\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.maxpooling1(x)\n        x = self.block1(x, training=training)\n        x = self.block2(x, training=training)\n        x = self.block3(x, training=training)\n        x = self.block4(x, training=training)\n        x = self.averagepooling(x)\n        x = self.dense(x)\n        output = tf.nn.softmax(x)\n        \n        return output  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ResNet50 class\nclass ResNet50(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = tf.keras.layers.Conv2D(\n            filters=64,\n            kernel_size=[7, 7],\n            strides=2,\n            padding=\"same\")\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.maxpooling1 = tf.keras.layers.MaxPool2D(\n            pool_size=[3, 3],\n            strides=2,\n            padding=\"same\")\n        # filters, num_block, strides\n        self.block1 = BlockBottleNeckxn(64, 3, 1)\n        self.block2 = BlockBottleNeckxn(128, 4, 2)\n        self.block3 = BlockBottleNeckxn(256, 6, 2)\n        self.block4 = BlockBottleNeckxn(512, 3, 2)\n        self.averagepooling = tf.keras.layers.GlobalAveragePooling2D()\n        self.dense = tf.keras.layers.Dense(units=NUM_CLASSES)\n        \n    def call(self, inputs, training=None):\n        x = tf.image.resize(inputs, [224, 224])\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.maxpooling1(x)\n        x = self.block1(x, training=training)\n        x = self.block2(x, training=training)\n        x = self.block3(x, training=training)\n        x = self.block4(x, training=training)\n        x = self.averagepooling(x)\n        x = self.dense(x)\n        \n        output = tf.nn.softmax(x)\n        \n        return output  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Selcetion"},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = ResNet18()\nmodel = ResNet34()\n# model = ResNet50()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data: CIFAR10"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data\n(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\nprint('x_train shape:', X_train.shape)\nprint('y_train shape:', y_train.shape)\nprint(X_train.shape[0], 'train samples')\nprint(X_test.shape[0], 'test samples')\n\nX_train = X_train/255.\nX_test = X_test/255.\n# one-hot coding\ny_train = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\ny_test = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compile"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n#     loss=tf.keras.losses.sparse_categorical_crossentropy,\n    loss=tf.keras.losses.categorical_crossentropy,\n#     metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n    metrics=[tf.keras.metrics.categorical_accuracy])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fit"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),steps_per_epoch=len(X_train)/BATCH_SIZE, epochs=EPOCHS, validation_data=(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reference  \n[Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}